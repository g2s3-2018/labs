{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring material properties of a cantilevered beam\n",
    "\n",
    "Recall the beam from last week. Previously, we fixed the material properties and inferred the applied load.  Here we flip the problem, the loads will be fixed and we will infer the material properties.\n",
    "\n",
    "<img src=\"BeamDrawing.png\" width=300px>\n",
    "\n",
    "### Formulation:\n",
    "\n",
    "Again, let $u(x)$ denote the vertical deflection of the beam and let $m(x)$ denote the vertial force acting on the beam at point $x$ (positive for upwards, negative for downwards).  We assume that the displacement can be well approximated using Euler-Bernoulli beam theory and thus satisfies the PDE\n",
    "$$\n",
    "\\frac{\\partial^2}{\\partial x^2}\\left[ \\exp[m(x)] \\frac{\\partial^2 u}{\\partial x^2}\\right] = f(x),\n",
    "$$\n",
    "where $E(x)=\\exp[m(x)]$ is an effective stiffness that depends both on the beam geometry and material properties.  Our goal is to infer $m(x)$ given a few point observations of $u(x)$ and a known load $f(x)$.\n",
    "\n",
    "The same cantilever boundary conditions are used as before.  These take the form\n",
    "$$\n",
    "u(x=0) = 0,\\quad \\left.\\frac{\\partial u}{\\partial x}\\right|_{x=0} = 0\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\left.\\frac{\\partial^2 u}{\\partial x^2}\\right|_{x=L} = 0, \\quad  \\left.\\frac{\\partial^3 u}{\\partial x^3}\\right|_{x=L} = 0.\n",
    "$$\n",
    "\n",
    "\n",
    "We assume that $m(x)$ is piecwise constant over $P$ nonoverlapping intervals on $[0,L]$.  More precisely,\n",
    "$$\n",
    "m(x) = \\sum_{i=1}^P m_i \\,I\\left(x\\in [a_i, a_{i+1})\\right),\n",
    "$$\n",
    "where $I(\\cdot)$ is an indicator function.  \n",
    "\n",
    "#### Prior\n",
    "For the prior, we assume each value is an independent normal random variable\n",
    "$$\n",
    "m_i \\sim N(\\mu_i, \\sigma_i^2).\n",
    "$$\n",
    "\n",
    "#### Likelihood\n",
    "Let $N_x$ denote the number of finite difference nodes used to discretize the Euler-Bernoulli PDE above.  For this problem, we will have observations of the solution $u(x)$ at $N_y$ of the finite difference nodes.  Let $u\\in\\mathbb{R}^{N_x}$ (without the $(x)$) denote a vector containing the finite difference solution and let $y\\in\\mathbb{R}^{N_y}$ denote the observable random variable, which is the solution $u$ at $N_y$ nodes plus some noise $\\epsilon$, i.e.\n",
    "$$\n",
    "y = Bu + \\epsilon,\n",
    "$$\n",
    "where $\\epsilon \\sim N(0, \\Sigma_y)$.  The solution vector $u$ is given by\n",
    "$$\n",
    "u = [K(m)]^{-1}f,\n",
    "$$\n",
    "where $K$ represents the discretization of the Euler-Bernoulli PDE as a function of $m$.  Combining this with the definition of $y$, we have the complete forward model\n",
    "$$\n",
    "y = B[K(m)]^{-1} f + \\epsilon\n",
    "$$\n",
    "\n",
    "The likelihood function then takes the form:\n",
    "$$\n",
    "p(y | m) = N\\left(\\, B [K(m)]^{-1} f,\\,\\,\\Sigma_y \\,\\right) \n",
    "$$\n",
    "\n",
    "\n",
    "#### Posterior\n",
    "Evaluating the posterior, which is simply written as \n",
    "$$\n",
    "p(m|y) \\propto p(y|m)p(m),\n",
    "$$\n",
    "involves several steps.  The computational graph below highlights the steps necessary to evaluate the posterior.  This graph is also similar to the one we will construct with MUQ below.\n",
    "\n",
    "<img src=\"PosteriorGraphStart.png\" width=500px>\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/fenics/Installations/MUQ_INSTALL/lib')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Import forward model class\n",
    "from BeamModel import EulerBernoulli\n",
    "\n",
    "# MUQ Includes\n",
    "import pymuqModeling as mm # Needed for Gaussian distribution\n",
    "import pymuqApproximation as ma # Needed for Gaussian processes\n",
    "import pymuqSamplingAlgorithms as ms # Needed for MCMC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and finite difference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('ProblemDefinition.h5','r')\n",
    "\n",
    "x = np.array( f['/ForwardModel/NodeLocations'] )\n",
    "B = np.array( f['/Observations/ObservationMatrix'] )\n",
    "obsData = np.array( f['/Observations/ObservationData'] )\n",
    "\n",
    "length = f['/ForwardModel'].attrs['BeamLength']\n",
    "radius = f['/ForwardModel'].attrs['BeamRadius']\n",
    "\n",
    "loads = np.array( f['/ForwardModel/Loads'])\n",
    "\n",
    "numObs = obsData.shape[0]\n",
    "numPts = x.shape[1]\n",
    "dim = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the material property intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numIntervals = 3\n",
    "endPts = np.linspace(0,1,numIntervals+1)\n",
    "intervals = [(endPts[i],endPts[i+1]) for i in range(numIntervals)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logPriorMu = 10*np.ones(numIntervals)\n",
    "logPriorCov = 4.0*np.eye(numIntervals)\n",
    "\n",
    "logPrior = mm.Gaussian(logPriorMu, logPriorCov).AsDensity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Fill in the __init__ and EvaluateImpl functions\n",
    "# HINT: Refer to the banana transformations from yesterday for syntax\n",
    "#\n",
    "\n",
    "class LumpedToFull(mm.PyModPiece):\n",
    "    \n",
    "    def __init__(self, intervals, pts):\n",
    "        \"\"\" \n",
    "        INPUTS:\n",
    "          - Intervals is a list of tuples containing the intervals that define the \n",
    "            parameter field. \n",
    "          - pts is a vector containing the locations of the finite difference nodes\n",
    "        \"\"\"\n",
    "            \n",
    "            \n",
    "    def EvaluateImpl(self, inputs):\n",
    "        \"\"\"\n",
    "        - inputs[0] will contain a vector with the values m_i in each interval\n",
    "        - Needs to compute a vector \"mField\" containing m at each of the finite difference nodes\n",
    "        - Should set the output using something like \"self.outputs = [ mField ]\"\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mField      = LumpedToFull(intervals, x )\n",
    "expmVals    = mm.ExpOperator(numIntervals)\n",
    "loadPiece   = mm.ConstantVector(loads)\n",
    "obsOperator = mm.DenseLinearOperator(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EulerBernoullie is a child of ModPiece with two inputs:\n",
    "# 1. A vector of loads at each finite difference node\n",
    "# 2. A vector containing the material property (exp(m(x))) at each finite difference node\n",
    "beamModel = EulerBernoulli(numPts, length, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseVar = 1e-4\n",
    "noiseCov = noiseVar*np.eye(obsData.shape[0])\n",
    "likelihood = mm.Gaussian(obsData, noiseCov).AsDensity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posteriorPiece = mm.DensityProduct(2)\n",
    "mPiece = mm.IdentityOperator(numIntervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to cast from non-held to held instance (T& to Holder<T>) of type 'std::shared_ptr<muq::Modeling::WorkPiece>''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-43bd43868fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmPiece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"m_i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpmVals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exp(m_i)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exp(m(x))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloadPiece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobsOperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to cast from non-held to held instance (T& to Holder<T>) of type 'std::shared_ptr<muq::Modeling::WorkPiece>''"
     ]
    }
   ],
   "source": [
    "graph = mm.WorkGraph()\n",
    "\n",
    "# Forward model nodes and edges\n",
    "graph.AddNode(mPiece, \"m_i\")\n",
    "graph.AddNode(expmVals, \"exp(m_i)\")\n",
    "graph.AddNode(mField, \"exp(m(x))\")\n",
    "graph.AddNode(loadPiece, \"f\")\n",
    "graph.AddNode(obsOperator, \"B\")\n",
    "graph.AddNode(beamModel, \"u\")\n",
    "\n",
    "graph.AddEdge(\"m_i\", 0, \"exp(m_i)\", 0)\n",
    "graph.AddEdge(\"exp(m_i)\", 0, \"exp(m(x))\", 0)\n",
    "graph.AddEdge(\"exp(m(x))\", 0, \"u\", 1)\n",
    "graph.AddEdge(\"f\", 0, \"u\", 0)\n",
    "graph.AddEdge(\"u\", 0, \"B\", 0)\n",
    "\n",
    "# Other nodes and edges\n",
    "graph.AddNode(likelihood, \"Likelihood\")\n",
    "graph.AddNode(logPrior, \"Prior\")\n",
    "graph.AddNode(posteriorPiece,\"Posterior\")\n",
    "\n",
    "graph.AddEdge(\"B\", 0, \"Likelihood\", 0)\n",
    "graph.AddEdge(\"m_i\", 0, \"Prior\", 0)\n",
    "graph.AddEdge(\"Prior\",0,\"Posterior\",0)\n",
    "graph.AddEdge(\"Likelihood\",0, \"Posterior\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.Visualize(\"PosteriorGraph.png\")\n",
    "Image(filename='PosteriorGraph.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = ms.SamplingProblem(graph.CreateModPiece(\"Posterior\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposalOptions = dict()\n",
    "proposalOptions['Method'] = 'AMProposal'\n",
    "proposalOptions['ProposalVariance'] = 1e-2\n",
    "proposalOptions['AdaptSteps'] = 100\n",
    "proposalOptions['AdaptStart'] = 1000\n",
    "proposalOptions['AdaptScale'] = 0.1\n",
    "\n",
    "kernelOptions = dict()\n",
    "kernelOptions['Method'] = 'MHKernel'\n",
    "kernelOptions['Proposal'] = 'ProposalBlock'\n",
    "kernelOptions['ProposalBlock'] = proposalOptions\n",
    "\n",
    "options = dict()\n",
    "options['NumSamples'] = 50000\n",
    "options['ThinIncrement'] = 1\n",
    "options['BurnIn'] = 10000\n",
    "options['KernelList'] = 'Kernel1'\n",
    "options['PrintLevel'] = 3\n",
    "options['Kernel1'] = kernelOptions\n",
    "\n",
    "mcmc = ms.SingleChainMCMC(options,problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startPt = 10.0*np.ones(numIntervals)\n",
    "samps = mcmc.Run(startPt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess = samps.ESS()\n",
    "print('Effective Sample Size = \\n', ess)\n",
    "\n",
    "sampMean = samps.Mean()\n",
    "print('\\nSample mean = \\n', sampMean)\n",
    "\n",
    "sampCov = samps.Covariance()\n",
    "print('\\nSample Covariance = \\n', sampCov)\n",
    "\n",
    "mcErr = np.sqrt( samps.Variance() / ess)\n",
    "print('\\nEstimated MC error in mean = \\n', mcErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampMat = samps.AsMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Plot the MCMC chain.  \n",
    "# RECALL: Each column of sampMat is one step in the chain\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Make scatter plots for each two-dimensional marginal of the chain\n",
    "# HINT: Try using the pandas scatter_matrix function\n",
    "#       https://pandas.pydata.org/pandas-docs/stable/visualization.html#visualization-scatter-matrix\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the autocorrelation of the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "for i in range(numIntervals):\n",
    "    shiftedSamp = sampMat[i,:]-np.mean(sampMat[i,:])\n",
    "    corr = np.correlate(shiftedSamp, shiftedSamp, mode='full')\n",
    "    plt.plot(corr[int(corr.size/2):]/np.max(corr), label='Dimension %d'%i)\n",
    "    \n",
    "maxLagPlot = 1500\n",
    "plt.plot(np.zeros(maxLagPlot),'--k', label='Zero')\n",
    "\n",
    "plt.xlim([0,maxLagPlot])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot samples of the posterior predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSamps = np.zeros((numPts, sampMat.shape[1]))\n",
    "\n",
    "predModel = graph.CreateModPiece(\"u\")\n",
    "\n",
    "for i in range(sampMat.shape[1]):\n",
    "    predSamps[:,i] = predModel.Evaluate([ sampMat[:,i] ])[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot quantiles\n",
    "plt.fill_between(x[0,:], \n",
    "                 np.percentile(predSamps,1,axis=1),\n",
    "                 np.percentile(predSamps,99,axis=1),\n",
    "                 edgecolor='none', label='1%-99% CI')\n",
    "\n",
    "# Plot the observations\n",
    "obsInds = np.where(B>0)[1]\n",
    "plt.plot(x[0,obsInds], obsData, 'xk', markerSize=10, label='Observations')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Location x')\n",
    "plt.ylabel('Displacement u')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
