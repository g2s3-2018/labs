{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring loads on an Euler Bernoulli beam\n",
    "\n",
    "Here we look at another linear Gaussian inverse problem, but one with a distributed parameter field and PDE forward model.  More specifically, the inverse problem is to infer the forces acting along a cantilevered beam.\n",
    "\n",
    "<div><img src=\"CantileverBeam.png\" width=\"500px\" style=\"padding-bottom:0.5em;\"/><br>Image courtesy of wikimedia.org</div>\n",
    "  \n",
    "\n",
    "\n",
    "### Formulation:\n",
    "\n",
    "Let $u(x)$ denote the vertical deflection of the beam and let $m(x)$ denote the vertial force acting on the beam at point $x$ (positive for upwards, negative for downwards).  We assume that the displacement can be well approximated using Euler-Bernoulli beam theory and thus satisfies the PDE\n",
    "$$\n",
    "\\frac{\\partial^2}{\\partial x^2}\\left[ E(x) \\frac{\\partial^2 u}{\\partial x^2}\\right] = m(x),\n",
    "$$\n",
    "where $E(x)$ is an effective stiffness that depends both on the beam geometry and material properties.  In this lab, we assume $E(x)$ is constant and $E(x)=10^5$.  However, in future labs, $E(x)$ will also be an inference target. \n",
    "\n",
    "For a beam of length $L$, the cantilever boundary conditions take the form\n",
    "$$\n",
    "u(x=0) = 0,\\quad \\left.\\frac{\\partial u}{\\partial x}\\right|_{x=0} = 0\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\left.\\frac{\\partial^2 u}{\\partial x^2}\\right|_{x=L} = 0, \\quad  \\left.\\frac{\\partial^3 u}{\\partial x^3}\\right|_{x=L} = 0.\n",
    "$$\n",
    "  \n",
    "Discretizing this PDE with finite differences (or finite elements, etc...), we obtain a linear system of the form\n",
    "$$\n",
    "Ku = m,\n",
    "$$\n",
    "where $u\\in\\mathbb{R}^N$ and $m\\in\\mathbb{R}^N$ are vectors containing approximations of $u(x)$ and $m(x)$ at the finite difference nodes.  \n",
    "\n",
    "Only $M$ components of the $N$ dimensional vector $u$ are observed.  To account for this, we introduce a sparse matrix $B$ that extracts $M$ unique components of $u$.  Combining this with an additive Gaussian noise model, we obtain  \n",
    "$$\n",
    "y = BK^{-1} m + \\epsilon,\n",
    "$$\n",
    "where $\\epsilon \\sim N(0,\\Sigma_y)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/fenics/Installations/MUQ_INSTALL/lib')\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# MUQ Includes\n",
    "import pymuqModeling as mm # Needed for Gaussian distribution\n",
    "import pymuqApproximation as ma # Needed for Gaussian processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read discretization and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('ProblemDefinition.h5','r')\n",
    "x = np.array( f['/ForwardModel/NodeLocations'] )\n",
    "K = np.array( f['/ForwardModel/SystemMatrix'] )\n",
    "B = np.array( f['/Observations/ObservationMatrix'] )\n",
    "obsData = np.array( f['/Observations/ObservationData'] )\n",
    "\n",
    "numObs = obsData.shape[0]\n",
    "numPts = x.shape[1]\n",
    "dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct components of the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsMat = np.linalg.solve(K,B.T).T\n",
    "noiseCov = 1e-12 * np.eye(numObs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Gaussian Process prior\n",
    "This is known apriori:\n",
    "- The true prior variance is 101\n",
    "- The loads are smooth with a constant offset.\n",
    "- The load is continuously differentiable\n",
    "\n",
    "Reference the Gaussian process notebook in this folder for syntax questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Construct the Gaussian process prior here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot prior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot several realizations of the prior at the finite difference nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute posterior\n",
    "A Gaussian Process defines a distribution over functions.  The Gaussian process class has a function `Discretize(x)` that will return a Gaussian distribution by evaluating the mean function and covariance kernel at the points contained in `x`. \n",
    "\n",
    "For usage of the `Gaussian` class and the `Condition` function, refer to the earlier linear regression notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Discretize the GP prior and condition the resulting Gaussian on the observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot posterior\n",
    "Look at the posterior spatially.  You might want to consider the mean, marginal standard deviation, or samples of the posterior.\n",
    "\n",
    "It might help to look at the documentation of matplotlib's `fill_between` function, available [here](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.fill_between.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the posterior.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate observation of load sum\n",
    "Assume you are now given an additional observation: the sum of the load vector $m$.\n",
    "Update the posterior distribution to reflect this new information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumObs = np.array( f['/Observations/LoadSum'] )\n",
    "sumNoiseVar = 1e-7 * np.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Construct an observation matrix and update the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the updated posterior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
